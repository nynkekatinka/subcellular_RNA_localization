{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gambino/students_workdir/nynke/miniconda3/envs/blurry/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# when debugging the python scripts, with the autoreload the jupyter notebook sync's to the most up to date scripts. See: https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import random\n",
    "from dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 101\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading RF Models & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata_all_spots = sc.read_h5ad(\"/media/gambino/students_workdir/nynke/data/all_spots_simulated_embeddings_adata.h5ad\")\n",
    "adata_split_cellID = sc.read_h5ad(\"/media/gambino/students_workdir/nynke/new_model_with_cell_id_left_out_custom_nynke_panel_simulated_embeddings_adata.h5ad\")\n",
    "#adata_mixed_cellID = sc.read_h5ad(\"/media/gambino/students_workdir/nynke/data/custom_nynke_panel_simulated_embeddings_adata.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_interval(interval):\n",
    "    if interval == '0-10':\n",
    "        return '0-10'\n",
    "    elif interval in ['10-20', '20-30']:\n",
    "        return '10-30'\n",
    "    elif interval in ['30-40', '40-50', '50-60']:\n",
    "        return '30-60'\n",
    "    elif interval in ['70-80', '80-90', '90-100']:\n",
    "        return '70-100'\n",
    "    elif interval == '100+':\n",
    "        return '100+'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def initialize_adata(adata):\n",
    "    choices = ['strong', 'intermediate', 'low']\n",
    "    conditions = [\n",
    "        (adata.obs['prop'] == 0.9) | ((adata.obs['prop'] == 0.4) & (adata.obs['pattern'] == 'protrusion')),\n",
    "        (adata.obs['prop'] == 0.5) | ((adata.obs['prop'] == 0.2) & (adata.obs['pattern'] == 'protrusion')),\n",
    "        (adata.obs['prop'] == 0.1) | ((adata.obs['prop'] == 0.0) & (adata.obs['pattern'] == 'protrusion'))\n",
    "    ]\n",
    "    adata.obs['pattern_strength'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    # Include modified RNA count intervals in the adata object\n",
    "    adata.obs['rna_count'] = adata.obs['n_spots_interval'].apply(map_interval)\n",
    "\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_interval(interval):\n",
    "    if interval == '0-10':\n",
    "        return '0-10'\n",
    "    elif interval in ['10-20', '20-30']:\n",
    "        return '10-30'\n",
    "    elif interval in ['30-40', '40-50', '50-60']:\n",
    "        return '30-60'\n",
    "    elif interval in ['70-80', '80-90', '90-100']:\n",
    "        return '70-100'\n",
    "    elif interval == '100+':\n",
    "        return '100+'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "adata_test.obs['rna_count'] = adata_test.obs['n_spots_interval'].apply(map_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the simulated genes (1 gene ~300 cells). Method can be found in dataprep.py\n",
    "# In this case, the genes contain all the counts, iso only low counts. \n",
    "pericellular_dict_split_cellID = subsetGenes(adata_split_cellID, 'pericellular', pattern_strength = \"strong\", mixed_counts = True)\n",
    "pericellular_dict_split_testID = subsetGenes(adata_split_cellID[adata_split_cellID.obs['cell_id'].isin(adata_split_cellID.uns['test_cellIDs'])], 'pericellular', pattern_strength = \"strong\", mixed_counts = True)\n",
    "random_dict_mixed = subsetGenes(adata, 'random', mixed_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate Probability Density Functions with KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use KDEpy, is a quicker to run than KDE implementations of scipy, sklearn and statsmodel, and you can use a bandwidth estimator called ISJ, which is useful for very non-normal data and potentially multimodal data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate, EstimatorSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 317 × 15\n",
       "    obs: 'pattern', 'random_or_pattern', 'n_spots', 'n_spots_interval', 'cell_id', 'genes', 'rotation', 'rotation_interval', 'blur', 'prop', 'prop_interval', 'corresponding_dapis', 'train_or_val', 'original_image_paths', 'pattern_strength'\n",
       "    uns: 'test_cellIDs', 'train_cellIDs'\n",
       "    obsm: 'latent'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pericellular_dict_split_cellID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = EstimatorSettings(efficient=True, n_jobs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use cross validation least squares to select the bandwidth for each dimension. Choose LS over ML because ML makes assumptions about normality etc, whereas LS does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomgene = KDEMultivariate(data=random_dict_mixed[0].obsm['latent'], var_type='ccccccccccccccc',bw='cv_ls', defaults=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "perigene = KDEMultivariate(data=pericellular_dict_split_cellID[0].obsm['latent'], var_type='ccccccccccccccc',bw='cv_ls', defaults=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KDE instance\n",
       "Number of variables: k_vars = 15\n",
       "Number of samples:   nobs = 317\n",
       "Variable types:      ccccccccccccccc\n",
       "BW selection method: cv_ls"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomgene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the grid to turn the KDE into PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming point_cloud_1 and point_cloud_2 are your two point clouds\n",
    "combined = np.concatenate([random_dict_mixed[0].obsm['latent'], pericellular_dict_split_cellID[0].obsm['latent']], axis=0)  # Combine the point clouds\n",
    "\n",
    "# Find the minimum and maximum values across all dimensions and points\n",
    "min_val = min(np.min(random_dict_mixed[0].obsm['latent']),np.min(pericellular_dict_split_cellID[0].obsm['latent']))\n",
    "max_val = max(np.max(random_dict_mixed[0].obsm['latent']),np.max(pericellular_dict_split_cellID[0].obsm['latent']))\n",
    "num_points = 100  # number of points in each latent dimension\n",
    "\n",
    "# Create the grid\n",
    "grid = np.linspace(min_val, max_val, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_random = randomgene.pdf(data_predict=grid)\n",
    "pdf_peri = perigene.pdf(data_predict=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chamfer Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_L1_distance(point_cloud_1, point_cloud_2):\n",
    "\n",
    "    # Compute all pairwise Manhattan distances, output matrix = [distance_cloudA1, distance_cloud2]\n",
    "    distances_1_to_2 = cdist(point_cloud_1, point_cloud_2, metric='cityblock')\n",
    "    distances_2_to_1 = cdist(point_cloud_2, point_cloud_1, metric='cityblock')\n",
    "\n",
    "    # Get nearest neighbor for each point from point cloud 1 in point cloud 2 and vice versa\n",
    "    distances_1_to_2 = np.min(distances_1_to_2, axis=1)\n",
    "    distances_2_to_1 = np.min(distances_2_to_1, axis=1)\n",
    "\n",
    "    # Compute the Chamfer distance\n",
    "    return np.mean(distances_1_to_2) + np.mean(distances_2_to_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.34175945445895\n"
     ]
    }
   ],
   "source": [
    "print(chamfer_L1_distance(random_dict_mixed[0].obsm['latent'], pericellular_dict_split_cellID[0].obsm['latent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.27557134989247\n"
     ]
    }
   ],
   "source": [
    "print(chamfer_L1_distance(random_dict_mixed[0].obsm['latent'], random_dict_mixed[2].obsm['latent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blurry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
